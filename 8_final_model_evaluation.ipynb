{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43688936",
   "metadata": {},
   "source": [
    "# Model Evaluation Final - Airbnb Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891df165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_curve, roc_auc_score, precision_recall_curve, precision_score, recall_score, average_precision_score\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({\"font.size\": 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d160d77",
   "metadata": {},
   "source": [
    "## Execution Time Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All thread\n",
    "# 32.9 s ± 2.7 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
    "# 2.54 s ± 6.02 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
    "# 5.41 s ± 105 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
    "# 6min 20s ± 3.26 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
    "# 4min 9s ± 2.65 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
    "\n",
    "# Single thread\n",
    "# 37.9 s ± 1.71 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
    "# 3.83 s ± 38.2 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
    "# 5.73 s ± 79.3 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
    "# 6min 19s ± 5.08 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
    "# 4min 22s ± 6.14 s per loop (mean ± std. dev. of 3 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['LOF', 'DBSCAN', 'iForest', 'OCSVM', 'SUOD']\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# Draw the plot\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "width = 0.3\n",
    "\n",
    "mean = [32.9, 2.54, 5.41, 380, 249]\n",
    "std = [2.7, 0.6, 0.12, 3.26, 2.65]\n",
    "rects1 = ax.bar(x, mean, yerr=std, width=0.3, align='center', alpha=0.8, ecolor='black', capsize=10)\n",
    "\n",
    "mean = [37.9, 3.83, 5.73, 379, 262]\n",
    "std = [1.71, 0.38, 0.79, 5.08, 6.14]\n",
    "rects2 = ax.bar(x+width, mean, yerr=std, width=0.3, align='center', alpha=0.8, ecolor='black', capsize=10)\n",
    "\n",
    "ax.set_xlabel('\\nTuned Outlier Detection Models')\n",
    "ax.set_ylabel('Execution Time in Seconds')\n",
    "ax.set_xticks(x+0.15)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title('Execution Time Comparison\\n')\n",
    "ax.legend( (rects1[0], rects2[0]), ('n_jobs=-1', 'n_jobs=1') )\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/execution_time_comparison_opt.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4cebdf",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"reviews_sample_labelled.csv\"\n",
    "df_label = pd.read_csv(filename, sep=\";\")\n",
    "df_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"reviews_outlier_predtions_final.csv\"\n",
    "df_pred = pd.read_csv(filename, sep=\";\")\n",
    "df_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26952c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(model, name):\n",
    "    y_true = df_label[\"label\"]\n",
    "    y_pred = df_pred[model]\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "    ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "\n",
    "    ax.set_title(f'Confusion Matrix for Tuned {name}\\n');\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ');\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['Inlier','Outlier'])\n",
    "    ax.yaxis.set_ticklabels(['Inlier','Outlier'])\n",
    "    plt.savefig(f'figures/confusion_matrix_tuned_{model}.png', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    print(f\"Model: {name} => Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407009af",
   "metadata": {},
   "source": [
    "### LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix(\"lof\", \"LOF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c827843",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix(\"dbscan\", \"DBSCAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c09833b",
   "metadata": {},
   "source": [
    "### iForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30696a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix(\"iforest\", \"iForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e3b842",
   "metadata": {},
   "source": [
    "### OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix(\"ocsvm\", \"OCSVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8aee2",
   "metadata": {},
   "source": [
    "### SUOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix(\"suod\", \"SUOD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c96c48",
   "metadata": {},
   "source": [
    "## ROC AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_length = len(df_label[\"label\"])\n",
    "\n",
    "lof_auc = roc_auc_score(df_label[\"label\"], df_pred[\"lof_score\"])\n",
    "dbscan_auc = roc_auc_score(df_label[\"label\"], df_pred[\"dbscan\"])\n",
    "iforest_auc = roc_auc_score(df_label[\"label\"], df_pred[\"iforest_score\"])\n",
    "ocsvm_auc = roc_auc_score(df_label[\"label\"], df_pred[\"ocsvm_score\"])\n",
    "suod_auc = roc_auc_score(df_label[\"label\"], df_pred[\"suod_score\"])\n",
    "\n",
    "# summarize scores\n",
    "print('LOF => ROC AUC=%.3f' % (lof_auc))\n",
    "print('DBSCAN => ROC AUC=%.3f' % (dbscan_auc))\n",
    "print('iForest => ROC AUC=%.3f' % (iforest_auc))\n",
    "print('OCSVM => ROC AUC=%.3f' % (ocsvm_auc))\n",
    "print('SUOD => ROC AUC=%.3f' % (suod_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "random_fpr, random_tpr, _ = roc_curve(df_label[\"label\"], [0]*sample_length)\n",
    "lof_fpr, lof_tpr, _ = roc_curve(df_label[\"label\"], df_pred[\"lof_score\"])\n",
    "dbscan_fpr, dbscan_tpr, _ = roc_curve(df_label[\"label\"], df_pred[\"dbscan\"])\n",
    "iforest_fpr, iforest_tpr, _ = roc_curve(df_label[\"label\"], df_pred[\"iforest_score\"])\n",
    "ocsvm_fpr, ocsvm_tpr, _ = roc_curve(df_label[\"label\"], df_pred[\"ocsvm_score\"])\n",
    "suod_fpr, suod_tpr, _ = roc_curve(df_label[\"label\"], df_pred[\"suod_score\"])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "# plot the roc curve for the model\n",
    "plt.plot(random_fpr, random_tpr, linestyle='--')\n",
    "plt.plot(lof_fpr, lof_tpr, label=f'LOF')\n",
    "plt.plot(dbscan_fpr, dbscan_tpr, label=f'DBSCAN')\n",
    "plt.plot(iforest_fpr, iforest_tpr, label=f'iForest')\n",
    "plt.plot(ocsvm_fpr, ocsvm_tpr, label=f'OCSVM')\n",
    "plt.plot(suod_fpr, suod_tpr, label=f'SUOD')\n",
    "\n",
    "# axis labels\n",
    "plt.xlabel('\\nFalse Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve\\n')\n",
    "plt.legend()\n",
    "plt.savefig(f'figures/roc_final.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06bfda3",
   "metadata": {},
   "source": [
    "## Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abeacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_auc = average_precision_score(df_label[\"label\"], df_pred[\"lof_score\"])\n",
    "dbscan_auc = average_precision_score(df_label[\"label\"], df_pred[\"dbscan\"])\n",
    "iforest_auc = average_precision_score(df_label[\"label\"], df_pred[\"iforest_score\"])\n",
    "ocsvm_auc = average_precision_score(df_label[\"label\"], df_pred[\"ocsvm_score\"])\n",
    "suod_auc = average_precision_score(df_label[\"label\"], df_pred[\"suod_score\"])\n",
    "\n",
    "# summarize scores\n",
    "print('LOF => PR AUC=%.3f' % (lof_auc))\n",
    "print('DBSCAN => PR AUC=%.3f' % (dbscan_auc))\n",
    "print('iForest => PR AUC=%.3f' % (iforest_auc))\n",
    "print('OCSVM => PR AUC=%.3f' % (ocsvm_auc))\n",
    "print('SUOD => PR AUC=%.3f' % (suod_auc))\n",
    "\n",
    "precision_lof, recall_lof, th_lof = precision_recall_curve(df_label[\"label\"], df_pred[\"lof_score\"])\n",
    "precision_dbscan, recall_dbscan, th_dbscan = precision_recall_curve(df_label[\"label\"], df_pred[\"dbscan\"])\n",
    "precision_iforest, recall_iforest, th_iforest = precision_recall_curve(df_label[\"label\"], df_pred[\"iforest_score\"])\n",
    "precision_ocsvm, recall_ocsvm, th_ocsvm = precision_recall_curve(df_label[\"label\"], df_pred[\"ocsvm_score\"])\n",
    "precision_suod, recall_suod, th_suod = precision_recall_curve(df_label[\"label\"], df_pred[\"suod_score\"])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0,1], [0.5,0.5], linestyle='--')\n",
    "plt.plot(recall_lof, precision_lof, label='LOF')\n",
    "plt.plot(recall_dbscan, precision_dbscan, label='DBSCAN')\n",
    "plt.plot(recall_iforest, precision_iforest, label='iForest')\n",
    "plt.plot(recall_ocsvm, precision_ocsvm, label='OCSVM')\n",
    "plt.plot(recall_suod, precision_suod, label='SUOD')\n",
    "\n",
    "plt.title('Precision-Recall Curve\\n')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('\\nRecall')\n",
    "plt.legend()\n",
    "plt.savefig(f'figures/precision_recall_curve_final.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6673c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw precision and recall plot\n",
    "def draw_precision_recall_plot(th, precision, recall, model):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(th, precision[:-1], label=\"Precision\")\n",
    "    plt.plot(th, recall[:-1], label=\"Recall\")\n",
    "    plt.title(f\"Precision-Recall vs Threshold Plot for Tuned {model}\\n\")\n",
    "    plt.xlabel(\"\\nThreshold\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.legend()\n",
    "#     plt.grid()\n",
    "    plt.savefig(f'figures/threshold_{model.lower()}_tuned.png')\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa22ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_precision_recall_plot(th_lof, precision_lof, recall_lof, \"LOF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_precision_recall_plot(th_iforest, precision_iforest, recall_iforest, \"iForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_precision_recall_plot(th_ocsvm, precision_ocsvm, recall_ocsvm, \"OCSVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c909f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_precision_recall_plot(th_suod, precision_suod, recall_suod, \"SUOD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b207f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85041d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
